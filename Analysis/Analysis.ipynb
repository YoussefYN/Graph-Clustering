{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_init = open('wiki-topcats-categories.txt','rt')\n",
    "filtered_data = pd.read_csv('filtered-wiki-topcats_f.txt', sep=\" \", header=None) \n",
    "clusters_formed = pd.read_csv('clusters_f.csv', header = None)\n",
    "unique_nodes = set(filtered_data[0].values).union(set(filtered_data[1].values))\n",
    "number_clusters = []\n",
    "cluster_category = []\n",
    "nodes_indexes = []\n",
    "categories = []\n",
    "with open('wiki-topcats-categories.txt','rt') as f: \n",
    "    node2cat = {}\n",
    "    for line in f:\n",
    "        name, lines = line.split(';')\n",
    "        nodes = list(map(int,(lines.split())))\n",
    "        count_edges = len(nodes)\n",
    "        nodes = list(filter(lambda x: int(x) in unique_nodes, nodes))\n",
    "        category_name = name.split(':')[1]\n",
    "        if len(nodes) != 0:\n",
    "            cluster_category.append(category_name)\n",
    "            number_clusters.append(len(nodes))\n",
    "            nodes_indexes.append(nodes)\n",
    "        for node in nodes:\n",
    "            if node in node2cat:\n",
    "                node2cat[node].append(category_name)\n",
    "            else:\n",
    "                node2cat[node] = [category_name]\n",
    "        categories.append([category_name, count_edges])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       number of nodes per cluster\n",
      "count                 15221.000000\n",
      "mean                     31.724131\n",
      "std                     224.723494\n",
      "min                       1.000000\n",
      "25%                       5.000000\n",
      "50%                      15.000000\n",
      "75%                      34.000000\n",
      "max                   26562.000000\n",
      "                  0\n",
      "count     71.000000\n",
      "mean    2112.690141\n",
      "std    11106.724215\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        9.000000\n",
      "75%      116.000000\n",
      "max    85164.000000\n"
     ]
    }
   ],
   "source": [
    "df_init = pd.DataFrame(list(zip(cluster_category, number_clusters)), columns = ['topic', 'number of nodes per cluster'])\n",
    "stat_init = df_init.describe()\n",
    "stat_algo = clusters_formed.groupby(clusters_formed[1]).count().describe()\n",
    "print(stat_init)\n",
    "print(stat_algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "count     57.000000\n",
      "mean    1137.263158\n",
      "std     5387.534178\n",
      "min        2.000000\n",
      "25%        6.000000\n",
      "50%       13.000000\n",
      "75%      154.000000\n",
      "max    30752.000000\n"
     ]
    }
   ],
   "source": [
    "#Statistics for outliers\n",
    "\n",
    "count_in_cluster = clusters_formed.groupby(clusters_formed[1]).count()\n",
    "outliers = ((count_in_cluster==1) | (count_in_cluster > 50000))\n",
    "stat_outliers = count_in_cluster[~outliers].describe()\n",
    "print(stat_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page names of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Chiasmal syndrome', 'Pinakion',\n",
      "       'LyndonHochschildSerre spectral sequence', 'Zariski's main theorem',\n",
      "       'FultonHansen connectedness theorem', 'Cayley's ruled cubic surface',\n",
      "       'Annulus theorem', 'Bing's recognition theorem', 'BergmanWeil formula',\n",
      "       'Gladden, Missouri',\n",
      "       ...\n",
      "       'The Temple (Old Orchard Beach, Maine)', 'Octagonal Poultry House',\n",
      "       'Follen Church Society-Unitarian Universalist', 'Falcon Tabernacle',\n",
      "       'Dunwoody Village', 'Banks & Shane', 'In From the Night',\n",
      "       'Keiji Fukuda', 'Firehouse No. 4 (Plainfield, New Jersey)',\n",
      "       'Engine Company No. 3'],\n",
      "      dtype='object', length=85164)\n"
     ]
    }
   ],
   "source": [
    "page_name = {int(line.split()[0]):\" \".join(line.split()[1:]) for line in open(\"wiki-topcats-page-names.txt\")}\n",
    "max_cluster_names = clusters_formed.groupby(clusters_formed[1]).groups[279122].map(page_name)\n",
    "print(max_cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making id_node and id_category for some further usage\n",
    "\n",
    "ids_categories = {idx:cat for idx,cat in enumerate(cluster_category)}\n",
    "idx_nodes = []\n",
    "for cat in ids_categories.keys():\n",
    "    for node in nodes_indexes[cat]:\n",
    "        idx_nodes.append((node,cat))\n",
    "df_filtered = pd.DataFrame(idx_nodes, columns = ['id_node', 'id_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusters explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Living_people</td>\n",
       "      <td>0.180405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Harvard_University_alumni</td>\n",
       "      <td>0.014443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Year_of_birth_missing_(living_people)</td>\n",
       "      <td>0.014126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Article_Feedback_Pilot</td>\n",
       "      <td>0.012106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>American_military_personnel_of_World_War_II</td>\n",
       "      <td>0.008102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>American_Jews</td>\n",
       "      <td>0.006857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>American_novelists</td>\n",
       "      <td>0.006799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>People_from_New_York_City</td>\n",
       "      <td>0.006317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>National_Association_of_Independent_Colleges_a...</td>\n",
       "      <td>0.006305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Columbia_University_alumni</td>\n",
       "      <td>0.006071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>American_people_of_Irish_descent</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Yale_University_alumni</td>\n",
       "      <td>0.005812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>American_journalists</td>\n",
       "      <td>0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>North_Central_Association_of_Colleges_and_Schools</td>\n",
       "      <td>0.005343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Guggenheim_Fellows</td>\n",
       "      <td>0.005284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>20th-century_mathematicians</td>\n",
       "      <td>0.005225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>American_people_of_English_descent</td>\n",
       "      <td>0.004838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>American_businesspeople</td>\n",
       "      <td>0.004756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Incorporated_cities_and_towns_in_California</td>\n",
       "      <td>0.004709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>American_political_writers</td>\n",
       "      <td>0.004685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Princeton_University_alumni</td>\n",
       "      <td>0.004626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>American_Roman_Catholics</td>\n",
       "      <td>0.004532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Fellows_of_the_Royal_Society</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Universities_and_colleges_accredited_by_the_So...</td>\n",
       "      <td>0.004474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>American_painters</td>\n",
       "      <td>0.004427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Harvard_University_faculty</td>\n",
       "      <td>0.004345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>American_historians</td>\n",
       "      <td>0.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>American_academics</td>\n",
       "      <td>0.004133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>American_poets</td>\n",
       "      <td>0.004086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Fellows_of_the_American_Academy_of_Arts_and_Sc...</td>\n",
       "      <td>0.004074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242</th>\n",
       "      <td>British_MPs_17271734</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10609</th>\n",
       "      <td>1940s_Western_films</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10610</th>\n",
       "      <td>International_Labour_Organization_conventions</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10611</th>\n",
       "      <td>National_volleyball_teams</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10615</th>\n",
       "      <td>American_hip_hop_musicians</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3708</th>\n",
       "      <td>Romanian_essayists</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6241</th>\n",
       "      <td>British_MPs_17341741</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10617</th>\n",
       "      <td>British_screenwriters</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10620</th>\n",
       "      <td>Chinese_actors</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10622</th>\n",
       "      <td>People_from_Staffordshire</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>Fitzroy_Football_Club_players</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10627</th>\n",
       "      <td>18th-century_actors</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10599</th>\n",
       "      <td>2006_World_Baseball_Classic_players</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10596</th>\n",
       "      <td>Members_of_the_Royal_Victorian_Order</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10593</th>\n",
       "      <td>Israeli_composers</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10592</th>\n",
       "      <td>Ukrainian_composers</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>PlayStation_2-only_games</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10590</th>\n",
       "      <td>People_from_Palermo_(city)</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10589</th>\n",
       "      <td>Italian_politicians</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10584</th>\n",
       "      <td>Oakland_Oaks_(baseball)_players</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10583</th>\n",
       "      <td>Karelian_Isthmus</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10582</th>\n",
       "      <td>People_educated_at_Newington_College</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10581</th>\n",
       "      <td>Australian_soccer_clubs</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>German_Resistance_members</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10579</th>\n",
       "      <td>Sydney_Olympic_players</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10577</th>\n",
       "      <td>Polish_writers</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10576</th>\n",
       "      <td>American_actors_of_Chinese_descent</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10575</th>\n",
       "      <td>Norwegian_lawyers</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10574</th>\n",
       "      <td>Norwegian_civil_servants</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12412</th>\n",
       "      <td>FC_Bayern_Munich_players</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12413 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0         1\n",
       "14                                         Living_people  0.180405\n",
       "87                             Harvard_University_alumni  0.014443\n",
       "69                 Year_of_birth_missing_(living_people)  0.014126\n",
       "96                                Article_Feedback_Pilot  0.012106\n",
       "38           American_military_personnel_of_World_War_II  0.008102\n",
       "344                                        American_Jews  0.006857\n",
       "12                                    American_novelists  0.006799\n",
       "525                            People_from_New_York_City  0.006317\n",
       "248    National_Association_of_Independent_Colleges_a...  0.006305\n",
       "91                            Columbia_University_alumni  0.006071\n",
       "137                     American_people_of_Irish_descent  0.006024\n",
       "57                                Yale_University_alumni  0.005812\n",
       "10                                  American_journalists  0.005660\n",
       "249    North_Central_Association_of_Colleges_and_Schools  0.005343\n",
       "260                                   Guggenheim_Fellows  0.005284\n",
       "545                          20th-century_mathematicians  0.005225\n",
       "1446                  American_people_of_English_descent  0.004838\n",
       "497                              American_businesspeople  0.004756\n",
       "733          Incorporated_cities_and_towns_in_California  0.004709\n",
       "1264                          American_political_writers  0.004685\n",
       "150                          Princeton_University_alumni  0.004626\n",
       "136                             American_Roman_Catholics  0.004532\n",
       "696                         Fellows_of_the_Royal_Society  0.004485\n",
       "208    Universities_and_colleges_accredited_by_the_So...  0.004474\n",
       "361                                    American_painters  0.004427\n",
       "519                           Harvard_University_faculty  0.004345\n",
       "382                                  American_historians  0.004298\n",
       "806                                   American_academics  0.004133\n",
       "237                                       American_poets  0.004086\n",
       "462    Fellows_of_the_American_Academy_of_Arts_and_Sc...  0.004074\n",
       "...                                                  ...       ...\n",
       "6242                                British_MPs_17271734  0.000012\n",
       "10609                                1940s_Western_films  0.000012\n",
       "10610      International_Labour_Organization_conventions  0.000012\n",
       "10611                          National_volleyball_teams  0.000012\n",
       "10615                         American_hip_hop_musicians  0.000012\n",
       "3708                                  Romanian_essayists  0.000012\n",
       "6241                                British_MPs_17341741  0.000012\n",
       "10617                              British_screenwriters  0.000012\n",
       "10620                                     Chinese_actors  0.000012\n",
       "10622                          People_from_Staffordshire  0.000012\n",
       "10624                      Fitzroy_Football_Club_players  0.000012\n",
       "10627                                18th-century_actors  0.000012\n",
       "10599                2006_World_Baseball_Classic_players  0.000012\n",
       "10596               Members_of_the_Royal_Victorian_Order  0.000012\n",
       "10593                                  Israeli_composers  0.000012\n",
       "10592                                Ukrainian_composers  0.000012\n",
       "3746                            PlayStation_2-only_games  0.000012\n",
       "10590                         People_from_Palermo_(city)  0.000012\n",
       "10589                                Italian_politicians  0.000012\n",
       "10584                    Oakland_Oaks_(baseball)_players  0.000012\n",
       "10583                                   Karelian_Isthmus  0.000012\n",
       "10582               People_educated_at_Newington_College  0.000012\n",
       "10581                            Australian_soccer_clubs  0.000012\n",
       "3722                           German_Resistance_members  0.000012\n",
       "10579                             Sydney_Olympic_players  0.000012\n",
       "10577                                     Polish_writers  0.000012\n",
       "10576                 American_actors_of_Chinese_descent  0.000012\n",
       "10575                                  Norwegian_lawyers  0.000012\n",
       "10574                           Norwegian_civil_servants  0.000012\n",
       "12412                           FC_Bayern_Munich_players  0.000012\n",
       "\n",
       "[12413 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = clusters_formed.groupby(clusters_formed[1])\n",
    "cluster_id = 279122\n",
    "descriptive_categories = {}\n",
    "for i in res.groups[cluster_id]:\n",
    "    node_id = clusters_formed.iloc[i][0]\n",
    "    categories_for_node = node2cat[node_id]\n",
    "    for category in categories_for_node:\n",
    "        if category in descriptive_categories:\n",
    "            descriptive_categories[category] += 1\n",
    "        else:\n",
    "            descriptive_categories[category] = 1\n",
    "sum_to_norm = len(res.groups[cluster_id])\n",
    "for i in descriptive_categories:\n",
    "    descriptive_categories[i] = descriptive_categories[i]/sum_to_norm\n",
    "descriptive_categories = pd.DataFrame([(k, v) for k,v in descriptive_categories.items()])\n",
    "descriptive_categories.sort_values(by=[1],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting anomalies with 2-sigma\n",
      "Anomalies clusters sizes [85164 27360 30752]\n",
      "Anomalies clusters IDs [ 279122 1181827 1205356]\n",
      "\n",
      "Detecting anomalies with DBSCAN\n",
      "Anomalies clusters sizes [ 1392 85164 27360 30752]\n",
      "Anomalies clusters IDs [   6283  279122 1181827 1205356]\n"
     ]
    }
   ],
   "source": [
    "clusters_counts = np.unique(clusters_formed.values[:, 1],\n",
    "                     return_counts=True)[1]\n",
    "clusters = np.unique(clusters_formed.values[:, 1],\n",
    "                     return_counts=True)[0]\n",
    "mean = np.mean(clusters_counts, axis=0)\n",
    "std = np.std(clusters_counts, axis=0)\n",
    "anomalies = np.any((clusters_counts < mean - 2*std,\n",
    "                              clusters_counts > mean + 2*std), axis=0)\n",
    "print(\"Detecting anomalies with 2-sigma\")\n",
    "print(\"Anomalies clusters sizes\", clusters_counts[anomalies])\n",
    "print(\"Anomalies clusters IDs\", clusters[anomalies])\n",
    "print()\n",
    "model = DBSCAN(min_samples=4, eps=500, p=1)\n",
    "model.fit(clusters_counts.reshape((-1, 1)))\n",
    "anomalies = model.labels_ == -1\n",
    "print(\"Detecting anomalies with DBSCAN\")\n",
    "print(\"Anomalies clusters sizes\", clusters_counts[anomalies])\n",
    "print(\"Anomalies clusters IDs\", clusters[anomalies])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
